---
title: "Homework 6"
output: github_document
---
```{r setup, include = FALSE}
library(tidyverse)
library(purrr)
library(rvest)
library(dplyr)
library(stringr)
library(modelr)
library(p8105.datasets)
library(gam)
library(purrr)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```



## Problem 1

load in the data
```{r}
homicide_df = 
  read_csv("homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
    ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
  
```

Start with one city.

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex,
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```


Try this across cities.

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(.x = data, ~glm(resolution ~ victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))
```

Plot some ORs

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
  
```


## Problem 2


Importing and tidying data
```{r}
birthweight_df = 
  read_csv("birthweight.csv") %>% 
  mutate(
    frace = as.factor(recode(frace,
                  `1` = "White",
                  `2` = "Black",
                  `3` = "Asian",
                  `4` = "Puerto Rican",
                  `8` = "Other"))
  ) %>% 
  mutate(
    mrace = as.factor(recode(mrace,
                  `1` = "White",
                  `2` = "Black",
                  `3` = "Asian",
                  `4` = "Puerto Rican",
                  `8` = "Other"))
  ) %>% 
  mutate(
    malform = as.factor(recode(malform,
                          `0` = "absent",
                          `1` = "present"))
  ) %>% 
  mutate(
    babysex = as.factor(recode(babysex,
                     `1` = "male",
                     `2` = "female"))
  ) %>% view()


sum(is.na(birthweight_df))
# no missing data points!!

```
Initial thoughts - not a lot of malformations, previous low birthweight babies, or prior small for gestational age babies

Thinking of looking into:

* gestational age (gaweeks) - this seems like it would be a highly predictive var given fetal development (they gain the most weight during the final trimester of gestation)
* blength - a 2012 [study](https://pubmed.ncbi.nlm.nih.gov/22535715/#:~:text=The%20addition%20of%20fetal%20length,%25%20versus%207.5%25%3B%20P%20%3C%20.) by Melamed et al. found that the addition of fetal length as a variable significantly improved their model's correlation with birth weight.
* mrace - also correlated with access to adequate care; Black mothers are more likely to have preterm and low-birthweight infants
* delwt - A 2010 [study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2974327/#:~:text=Observational%20studies%20have%20generally%20found,birth%20weight%20or%20infant%20adiposity.&text=Moreover%2C%20maternal%20adiposity%20tends%20to,BMI29%20than%20paternal%20adiposity.) found that maternal weight gain during pregnancy increases infant birthweight
* smoken - smoking has deleterious effects on pregnancy, including increasing the risk of preterm births and low birthweight (CDC)
* babysex - male infants typically have higher birthweight than female infants
* ppbmi - pre-pregnancy bmi [is often predictive](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2974327/#:~:text=Observational%20studies%20have%20generally%20found,birth%20weight%20or%20infant%20adiposity.&text=Moreover%2C%20maternal%20adiposity%20tends%20to,BMI29%20than%20paternal%20adiposity.) of infant birthweight
* fincome may be predictive of access to resources (esp during pregnancy), including medical care, adequate nutrition, etc. 
* parity [is a signficiant predictor](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3922415/#:~:text=Maternal%20parity%20is%20a%20well,infants%20born%20to%20nulliparous%20women.) of birthweight
* baby head is also predictive of bw based on what I remember from my Global Health nutrition case studies


Some exploration to visualize chosen vars (replaced different x vars using this same structure)
```{r}
birthweight_df %>% 
  ggplot(aes(x = gaweeks, y = bwt)) +
  geom_point()
```


let's try fitting a model
```{r}
bw_model_1 = lm(bwt ~ delwt + blength + gaweeks + mrace + smoken + babysex + ppbmi + fincome + parity + bhead, data = birthweight_df)
```

and visualize it:
```{r}
bw_model_1 %>% 
  broom::tidy() %>% 
summary(bw_model_1)
coef(bw_model_1)
```

This shows us that maternal weight, infant length, gestational age, male sex, smoking, pre-pregnancy BMI, family income, parity, and Black race are all signficantly associated with infant birthweight. 

I considered but ultimately didn't include several factors based on the fact that they were not significantly associated with infant birthweight based on the summary of my model. I combined background info/research with a little bit of trial and error to come up with this model. Unclear as to whether this model is truly optimal. 

Plotting this model:
```{r}
birthweight_df %>% 
modelr::add_residuals(bw_model_1) %>% 
  add_predictions(bw_model_1, var = "pred", type = NULL) %>% 
  add_residuals(model = bw_model_1, var = "resid") %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  labs(
    x = "fitted values",
    y = "residuals",
    title = "Residuals against fitted values"
  )
  

```


Now, compare to model using length at birth and gestational age as predictors
```{r}
bw_model_2 = lm(bwt ~ blength + gaweeks, data = birthweight_df)
```

And compare to model using head circumference, length, sex, and all interactions (including 3-way interaction) between

```{r}
bw_model_3 = lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = birthweight_df)
```

And now to cross-validate
```{r}
cv_df = 
  crossv_mc(birthweight_df, 100)

cv_df2 = 
  cv_df %>% 
  mutate(
    bw_model_1 = map(.x = train, ~lm(bwt ~ delwt + blength + gaweeks + mrace + smoken + babysex + ppbmi + fincome + parity, data = .x)),
    bw_model_2 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    bw_model_3 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = .x))
    ) %>% 
   mutate(
    rmse_model1 = map2_dbl(.x = bw_model_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(.x = bw_model_2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(.x = bw_model_3, .y = test, ~rmse(model = .x, data = .y))
  )

cv_df2 %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() + 
  labs(
    x = "model",
    y = "rmse",
    title = "rmse values for models 1 to 3 (L to R)"
  )


```
Based on this figure, it would appear that model 3 has the lowest median RMSE value, while model 2 has the highest. 


## Problem 3

download dataset, fit model to dataset, make sure can compute adjusted r-sq (comes from broom::glance), broom::tidy, estimated coefficients, rearrange things so have intercept and slope next to each other that you can multiply and take the log of. 

Import dataset, drop the nas, and select tmin and tmax
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything()) 
  
```

Bootstrap - find r-squared
```{r}
r_sq_boot = 
weather_df %>% 
  bootstrap(5000, id = "strap_number") %>% 
  mutate(
  models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
  results = map(models, broom::glance)
  ) %>% 
  unnest(results) %>% 
  select(r.squared)
```

Display distribution of r-sq values
```{r}
r_sq_boot %>% 
  ggplot(aes(x = r.squared)) + 
  geom_density() +
  labs(
    x = "r-squared values",
    title = "Distribution of r-squared values"
  )
```

The r-squared values appear to be normally distributed with a left skew and a median value around 0.913.

Now, onto finding log(β̂ 0∗β̂ 1)
```{r}
log_boot =
  weather_df %>% 
  bootstrap(5000, id = "strap_number") %>% 
  mutate(
  models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
  results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results) %>% 
  unnest(results)
```

manipulate these results to find the log
```{r}
log_boot_results = 
log_boot %>% 
  unnest() %>% 
  select(term, estimate) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>% 
  unnest() %>% 
  rename(
    intercept = "(Intercept)"
  ) %>% 
  mutate(
    log_est = log(intercept*tmin)
  )
# I tried to do this first with tmin~tmax, but it produced negative values only, which meant that my log function wouldn't work. Switched it around and it finally worked. 
```

plot the log distribution
```{r}
log_boot_results %>% 
  ggplot(aes(x = log_est)) + 
  geom_density() +
  labs(
    x = "logB0*B1 values",
    title = "Distribution of logB0*B1 values"
  )
```

These log values appear to be fairly normally and symmetrically distributed, with a median around 2.02. 


Let's find confidence intervals
```{r}
# for log




```

