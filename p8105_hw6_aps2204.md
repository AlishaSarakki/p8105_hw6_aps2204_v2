Homework 6
================

## Problem 1

load in the data

``` r
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
    ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_double(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_double(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

Start with one city.

``` r
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex,
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

| term              |    OR | CI\_lower | CI\_upper |
| :---------------- | ----: | --------: | --------: |
| (Intercept)       | 1.363 |     0.975 |     1.907 |
| victim\_age       | 0.993 |     0.987 |     1.000 |
| victim\_raceWhite | 2.320 |     1.648 |     3.268 |
| victim\_sexMale   | 0.426 |     0.325 |     0.558 |

Try this across cities.

``` r
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(.x = data, ~glm(resolution ~ victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))
```

Plot some ORs

``` r
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

<img src="p8105_hw6_aps2204_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

## Problem 2

Importing and tidying data

``` r
birthweight_df = 
  read_csv("data/birthweight.csv") %>% 
  mutate(
    frace = as.factor(recode(frace,
                  `1` = "White",
                  `2` = "Black",
                  `3` = "Asian",
                  `4` = "Puerto Rican",
                  `8` = "Other"))
  ) %>% 
  mutate(
    mrace = as.factor(recode(mrace,
                  `1` = "White",
                  `2` = "Black",
                  `3` = "Asian",
                  `4` = "Puerto Rican",
                  `8` = "Other"))
  ) %>% 
  mutate(
    malform = as.factor(recode(malform,
                          `0` = "absent",
                          `1` = "present"))
  ) %>% 
  mutate(
    babysex = as.factor(recode(babysex,
                     `1` = "male",
                     `2` = "female"))
  ) %>% view()
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
sum(is.na(birthweight_df))
```

    ## [1] 0

``` r
# no missing data points!!
```

Initial thoughts - not a lot of malformations, previous low birthweight
babies, or prior small for gestational age babies

Thinking of looking into:

  - gestational age (gaweeks) - this seems like it would be a highly
    predictive var given fetal development (they gain the most weight
    during the final trimester of gestation)
  - blength - a 2012
    [study](https://pubmed.ncbi.nlm.nih.gov/22535715/#:~:text=The%20addition%20of%20fetal%20length,%25%20versus%207.5%25%3B%20P%20%3C%20.)
    by Melamed et al. found that the addition of fetal length as a
    variable significantly improved their model’s correlation with birth
    weight.
  - mrace - also correlated with access to adequate care; Black mothers
    are more likely to have preterm and low-birthweight infants
  - delwt - A 2010
    [study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2974327/#:~:text=Observational%20studies%20have%20generally%20found,birth%20weight%20or%20infant%20adiposity.&text=Moreover%2C%20maternal%20adiposity%20tends%20to,BMI29%20than%20paternal%20adiposity.)
    found that maternal weight gain during pregnancy increases infant
    birthweight
  - smoken - smoking has deleterious effects on pregnancy, including
    increasing the risk of preterm births and low birthweight (CDC)
  - babysex - male infants typically have higher birthweight than female
    infants
  - ppbmi - pre-pregnancy bmi [is often
    predictive](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2974327/#:~:text=Observational%20studies%20have%20generally%20found,birth%20weight%20or%20infant%20adiposity.&text=Moreover%2C%20maternal%20adiposity%20tends%20to,BMI29%20than%20paternal%20adiposity.)
    of infant birthweight
  - fincome may be predictive of access to resources (esp during
    pregnancy), including medical care, adequate nutrition, etc.
  - parity [is a signficiant
    predictor](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3922415/#:~:text=Maternal%20parity%20is%20a%20well,infants%20born%20to%20nulliparous%20women.)
    of birthweight
  - baby head is also predictive of bw based on what I remember from my
    Global Health nutrition case studies

Some exploration to visualize chosen vars (replaced different x vars
using this same structure)

``` r
birthweight_df %>% 
  ggplot(aes(x = gaweeks, y = bwt)) +
  geom_point() +
  labs(
    x = "gestational age in weeks",
    y = "birthweight",
    title = "Visualization Model"
  )
```

<img src="p8105_hw6_aps2204_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

let’s try fitting a model

``` r
bw_model_1 = lm(bwt ~ delwt + blength + gaweeks + mrace + smoken + babysex + ppbmi + fincome + parity + bhead, data = birthweight_df)
```

and visualize it:

``` r
bw_model_1 %>% 
  broom::tidy() %>% 
summary(bw_model_1)
```

    ##      term              estimate           std.error          statistic      
    ##  Length:13          Min.   :-5727.781   Min.   :  0.1741   Min.   :-53.380  
    ##  Class :character   1st Qu.:  -22.517   1st Qu.:  1.4593   1st Qu.: -3.314  
    ##  Mode  :character   Median :    0.295   Median :  3.4463   Median :  1.696  
    ##                     Mean   : -420.456   Mean   : 22.7721   Mean   :  2.172  
    ##                     3rd Qu.:   74.409   3rd Qu.: 42.3169   3rd Qu.:  8.061  
    ##                     Max.   :  131.040   Max.   :107.3019   Max.   : 38.023  
    ##     p.value       
    ##  Min.   :0.00000  
    ##  1st Qu.:0.00000  
    ##  Median :0.00000  
    ##  Mean   :0.07209  
    ##  3rd Qu.:0.07875  
    ##  Max.   :0.61962

``` r
coef(bw_model_1)
```

    ##       (Intercept)             delwt           blength           gaweeks 
    ##     -5727.7809667         3.6005510        74.9195833        11.7634992 
    ##        mraceBlack mracePuerto Rican        mraceWhite            smoken 
    ##       -63.8177758       -22.5167413        74.4089094        -4.8517834 
    ##       babysexmale             ppbmi           fincome            parity 
    ##       -28.0177750       -12.4641712         0.2952626        97.4929351 
    ##             bhead 
    ##       131.0397086

This shows us that maternal weight, infant length, gestational age, male
sex, smoking, pre-pregnancy BMI, family income, parity, and Black race
are all signficantly associated with infant birthweight.

I considered but ultimately didn’t include several factors based on the
fact that they were not significantly associated with infant birthweight
based on the summary of my model. I combined background info/research
with a little bit of trial and error to come up with this model. Unclear
as to whether this model is truly optimal.

Plotting this model:

``` r
birthweight_df %>% 
modelr::add_residuals(bw_model_1) %>% 
  add_predictions(bw_model_1, var = "pred", type = NULL) %>% 
  add_residuals(model = bw_model_1, var = "resid") %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  labs(
    x = "fitted values",
    y = "residuals",
    title = "Residuals against fitted values"
  )
```

<img src="p8105_hw6_aps2204_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

Now, compare to model using length at birth and gestational age as
predictors

``` r
bw_model_2 = lm(bwt ~ blength + gaweeks, data = birthweight_df)
```

And compare to model using head circumference, length, sex, and all
interactions (including 3-way interaction) between

``` r
bw_model_3 = lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = birthweight_df)
```

And now to cross-validate

``` r
cv_df = 
  crossv_mc(birthweight_df, 100)

cv_df2 = 
  cv_df %>% 
  mutate(
    bw_model_1 = map(.x = train, ~lm(bwt ~ delwt + blength + gaweeks + mrace + smoken + babysex + ppbmi + fincome + parity, data = .x)),
    bw_model_2 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    bw_model_3 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = .x))
    ) %>% 
   mutate(
    rmse_model1 = map2_dbl(.x = bw_model_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(.x = bw_model_2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(.x = bw_model_3, .y = test, ~rmse(model = .x, data = .y))
  )

cv_df2 %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() + 
  labs(
    x = "model",
    y = "rmse",
    title = "rmse values for models 1 to 3 (L to R)"
  )
```

<img src="p8105_hw6_aps2204_files/figure-gfm/unnamed-chunk-12-1.png" width="90%" />

Based on this figure, it would appear that model 3 has the lowest median
RMSE value, while model 2 has the highest.

## Problem 3

download dataset, fit model to dataset, make sure can compute adjusted
r-sq (comes from broom::glance), broom::tidy, estimated coefficients,
rearrange things so have intercept and slope next to each other that you
can multiply and take the log of.

Import dataset

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything()) 
```

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

    ## using cached file: /Users/alishasarakki/Library/Caches/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2020-10-03 14:47:12 (7.522)

    ## file min/max dates: 1869-01-01 / 2020-10-31

Bootstrap - find r-squared

``` r
r_sq_boot = 
weather_df %>% 
  bootstrap(5000, id = "strap_number") %>% 
  mutate(
  models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
  results = map(models, broom::glance)
  ) %>% 
  unnest(results) %>% 
  select(r.squared)
```

Display distribution of r-sq values

``` r
r_sq_boot %>% 
  ggplot(aes(x = r.squared)) + 
  geom_density() +
  labs(
    x = "r-squared values",
    title = "Distribution of r-squared values"
  )
```

<img src="p8105_hw6_aps2204_files/figure-gfm/unnamed-chunk-15-1.png" width="90%" />

The r-squared values appear to be normally distributed with a slight
left skew and a median value around 0.913.

Now, onto finding log(β̂ 0∗β̂ 1)

``` r
log_boot =
  weather_df %>% 
  bootstrap(5000, id = "strap_number") %>% 
  mutate(
  models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
  results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results) %>% 
  unnest(results)
```

manipulate these results to find the log

``` r
log_boot_results = 
log_boot %>% 
  unnest() %>% 
  select(term, estimate) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>% 
  unnest() %>% 
  rename(
    intercept = "(Intercept)"
  ) %>% 
  mutate(
    log_est = log(intercept*tmin)
  )
```

    ## Warning: `cols` is now required when using unnest().
    ## Please use `cols = c()`

    ## Warning: Values are not uniquely identified; output will contain list-cols.
    ## * Use `values_fn = list` to suppress this warning.
    ## * Use `values_fn = length` to identify where the duplicates arise
    ## * Use `values_fn = {summary_fun}` to summarise duplicates

    ## Warning: `cols` is now required when using unnest().
    ## Please use `cols = c(`(Intercept)`, tmin)`

``` r
log_boot_results
```

    ## # A tibble: 5,000 x 3
    ##    intercept  tmin log_est
    ##        <dbl> <dbl>   <dbl>
    ##  1      7.16  1.04    2.01
    ##  2      7.47  1.01    2.02
    ##  3      6.86  1.06    1.98
    ##  4      6.89  1.06    1.99
    ##  5      7.44  1.03    2.04
    ##  6      7.18  1.05    2.02
    ##  7      7.03  1.05    2.00
    ##  8      7.37  1.01    2.00
    ##  9      7.48  1.02    2.03
    ## 10      7.06  1.04    1.99
    ## # … with 4,990 more rows

``` r
# I tried to do this first with tmin~tmax, but it produced negative values only, which meant that my log function wouldn't work. Switched it around and it finally worked. 
```

plot the log distribution

``` r
log_boot_results %>% 
  ggplot(aes(x = log_est)) + 
  geom_density() +
  labs(
    x = "logB0*B1 values",
    title = "Distribution of logB0*B1 values"
  )
```

<img src="p8105_hw6_aps2204_files/figure-gfm/unnamed-chunk-18-1.png" width="90%" />

These log values appear to be fairly normally and symmetrically
distributed, with a median around 2.02.

Let’s find confidence intervals

``` r
# CI for log estimates

CI_log = 
log_boot_results %>% 
  summarize(
    ci_lower = quantile(log_est, 0.025),
    ci_upper = quantile(log_est, 0.975)
  ) %>% 
  knitr::kable()

CI_log
```

| ci\_lower | ci\_upper |
| --------: | --------: |
|  1.966182 |  2.058477 |

``` r
CI_rsq = 
  r_sq_boot %>% 
  summarize(
       ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)
  ) %>% 
  knitr::kable()


CI_rsq
```

| ci\_lower | ci\_upper |
| --------: | --------: |
| 0.8938601 | 0.9271755 |

  - The 95% CI for log(β̂ 0∗β̂ 1) is (1.965118, 2.05854).
  - The 95% CI for r squared is (0.8943899, 0.9269525).
